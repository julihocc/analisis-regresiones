{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Métricas de Evaluación - Ejemplos prácticos",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRvvUQMOpYSq"
      },
      "source": [
        "#¿Qué veremos hoy?\n",
        "\n",
        "Responderé las pregunta: ¿Cómo puedo evaluar correctamente un modelo? y ¿Cómo puedo ajustar el modelo a los atributos más relevantes?, ¿esto me entregará una mejor evaluación?\n",
        "\n",
        "Para esto veremos lo siguiente:\n",
        "\n",
        "*   Métricas de Evaluación\n",
        "*   Selección de Características (Atributos)\n",
        "*   Lecturas recomendadas\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JeM3vJ3D3li"
      },
      "source": [
        "#**Métricas de Evaluación**\n",
        "\n",
        "Tenemos varías métricas de evaluación para modelos de machine learning:\n",
        "\n",
        "\n",
        "1.   Matriz de Confusión\n",
        "2.   Exactitud (Accuracy)\n",
        "3.   Precisión\n",
        "3.   Sensibilidad (Recall)\n",
        "4.   Puntuación F1 (F1 Score)\n",
        "5.  Entre otras ¿Puedes investigarlas? **Consejo**: \"La [documentación](https://scikit-learn.org/stable/modules/model_evaluation.html) es tu mejor amiga :D\"\n",
        "\n",
        "**Encuentra mayor información en este post de mi blog: https://machinelearningenespanol.com/2021/01/12/evaluacion-de-modelos-predictivos/**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9UxX-h0GRqe"
      },
      "source": [
        "#Matriz de Confusión\n",
        "\n",
        "Por definición la matriz de confusión $C$ se construye de forma que el elemento $C_{i,j}$ es igual al número de observaciones *verdaderas* del grupo $i$, y clasificadas en el grupo $j$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njEzBHNcEfXd",
        "outputId": "b489f94a-04d0-4651-d034-e24ee86ada99"
      },
      "source": [
        "# Matriz de Confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_true = [\"gato\", \"lobo\", \"gato\", \"gato\", \"lobo\", \"perro\"] # i => Renglones\n",
        "y_pred = [\"lobo\", \"lobo\", \"gato\", \"gato\", \"lobo\", \"gato\"]  # j => Columnas\n",
        "confusion_matrix(y_true, y_pred, labels=[\"lobo\", \"perro\", \"gato\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPA4eE-mJxyc"
      },
      "source": [
        "**Ejercicio Práctico**. Construir la matriz de confusión para el *dataset* digits. Sugerencias: Prueba usar Máquinas de vectores de Soporte SVM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "H-5whuv6EtBc",
        "outputId": "f3c41234-3a42-4edb-beb8-9e69071d75d2"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "plt.gray() \n",
        "plt.matshow(digits.images[0]) \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1797, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAL1UlEQVR4nO3df6hX9R3H8ddrptVS0laL0MiMIUSw/IEsitg0w1a4f5YoFCw29I8tkg3K9s/ov/6K9scIxGpBZqQljNhaSkYMtprXbJnaKDFSKgsNsz+U7L0/vsdhznXPvZ3P537v9/18wBe/997vPe/3vdfX95zz/Z5z3o4IARhs3xrrBgCUR9CBBAg6kABBBxIg6EACBB1IoC+CbnuJ7bdtv2N7TeFaj9k+ZHtXyTqn1bvc9jbbu22/ZfuewvXOs/2a7Teaeg+UrNfUnGD7ddvPl67V1Ntv+03bO21vL1xrqu1Ntvfa3mP7uoK1Zjc/06nbUdurO1l4RIzpTdIESe9KmiVpkqQ3JF1dsN6NkuZK2lXp57tM0tzm/hRJ/y7881nS5Ob+REmvSvpB4Z/x15KekvR8pd/pfkkXV6r1hKRfNPcnSZpaqe4ESR9KuqKL5fXDGn2BpHciYl9EnJD0tKSflCoWEa9IOlxq+Wep90FE7GjufyZpj6TpBetFRBxrPpzY3IodFWV7hqRbJa0rVWOs2L5QvRXDo5IUESci4tNK5RdJejci3utiYf0Q9OmS3j/t4wMqGISxZHumpDnqrWVL1plge6ekQ5K2RETJeg9LulfSlwVrnCkkvWh7yPbKgnWulPSxpMebXZN1ti8oWO90yyVt6Gph/RD0FGxPlvSspNURcbRkrYg4GRHXSpohaYHta0rUsX2bpEMRMVRi+V/jhoiYK+kWSb+0fWOhOueot5v3SETMkfS5pKKvIUmS7UmSlkra2NUy+yHoByVdftrHM5rPDQzbE9UL+fqIeK5W3WYzc5ukJYVKXC9pqe396u1yLbT9ZKFa/xURB5t/D0narN7uXwkHJB04bYtok3rBL+0WSTsi4qOuFtgPQf+npO/ZvrJ5Jlsu6U9j3FNnbFu9fbw9EfFQhXqX2J7a3D9f0mJJe0vUioj7I2JGRMxU7+/2UkTcUaLWKbYvsD3l1H1JN0sq8g5KRHwo6X3bs5tPLZK0u0StM6xQh5vtUm/TZExFxBe2fyXpr+q90vhYRLxVqp7tDZJ+KOli2wck/S4iHi1VT7213p2S3mz2myXptxHx50L1LpP0hO0J6j2RPxMRVd72quRSSZt7z586R9JTEfFCwXp3S1rfrIT2SbqrYK1TT16LJa3qdLnNS/kABlg/bLoDKIygAwkQdCABgg4kQNCBBPoq6IUPZxyzWtSj3ljX66ugS6r5y6z6h6Me9cayXr8FHUABRQ6YsT3QR+FMmzZtxN9z/PhxnXvuuaOqN336yE/mO3z4sC666KJR1Tt6dOTn3Bw7dkyTJ08eVb2DB0d+akNEqDk6bsROnjw5qu8bLyLif34xY34I7Hh00003Va334IMPVq23devWqvXWrCl+QthXHDlypGq9fsCmO5AAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBFoFvebIJADdGzbozUUG/6DeJWivlrTC9tWlGwPQnTZr9KojkwB0r03Q04xMAgZVZye1NCfK1z5nF0ALbYLeamRSRKyVtFYa/NNUgfGmzab7QI9MAjIYdo1ee2QSgO612kdv5oSVmhUGoDCOjAMSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kACTWkah9uSUWbNmVa03mpFT38Thw4er1lu2bFnVehs3bqxa72xYowMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCCBNiOZHrN9yPauGg0B6F6bNfofJS0p3AeAgoYNekS8IqnuWQcAOsU+OpAAs9eABDoLOrPXgP7FpjuQQJu31zZI+ruk2bYP2P55+bYAdKnNkMUVNRoBUA6b7kACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEhiI2Wvz5s2rWq/2LLSrrrqqar19+/ZVrbdly5aq9Wr/f2H2GoAqCDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpBAm4tDXm57m+3dtt+yfU+NxgB0p82x7l9I+k1E7LA9RdKQ7S0RsbtwbwA60mb22gcRsaO5/5mkPZKml24MQHdGtI9ue6akOZJeLdEMgDJan6Zqe7KkZyWtjoijZ/k6s9eAPtUq6LYnqhfy9RHx3Nkew+w1oH+1edXdkh6VtCciHirfEoCutdlHv17SnZIW2t7Z3H5cuC8AHWoze+1vklyhFwCFcGQckABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEEBmL22rRp06rWGxoaqlqv9iy02mr/PjNijQ4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEE2lwF9jzbr9l+o5m99kCNxgB0p82x7sclLYyIY8313f9m+y8R8Y/CvQHoSJurwIakY82HE5sbAxqAcaTVPrrtCbZ3SjokaUtEMHsNGEdaBT0iTkbEtZJmSFpg+5ozH2N7pe3ttrd33SSAb2ZEr7pHxKeStklacpavrY2I+RExv6vmAHSjzavul9ie2tw/X9JiSXtLNwagO21edb9M0hO2J6j3xPBMRDxfti0AXWrzqvu/JM2p0AuAQjgyDkiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAsxeG4WtW7dWrTfoav/9jhw5UrVeP2CNDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQRaB70Z4vC6bS4MCYwzI1mj3yNpT6lGAJTTdiTTDEm3SlpXth0AJbRdoz8s6V5JXxbsBUAhbSa13CbpUEQMDfM4Zq8BfarNGv16SUtt75f0tKSFtp8880HMXgP617BBj4j7I2JGRMyUtFzSSxFxR/HOAHSG99GBBEZ0KamIeFnSy0U6AVAMa3QgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkMxOy12rO05s2bV7VebbVnodX+fW7cuLFqvX7AGh1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJtDoEtrnU82eSTkr6gks6A+PLSI51/1FEfFKsEwDFsOkOJNA26CHpRdtDtleWbAhA99puut8QEQdtf1fSFtt7I+KV0x/QPAHwJAD0oVZr9Ig42Px7SNJmSQvO8hhmrwF9qs001QtsTzl1X9LNknaVbgxAd9psul8qabPtU49/KiJeKNoVgE4NG/SI2Cfp+xV6AVAIb68BCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUjAEdH9Qu3uF/o1Zs2aVbOctm/fXrXeqlWrqta7/fbbq9ar/febP3+wT8eICJ/5OdboQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSKBV0G1Ptb3J9l7be2xfV7oxAN1pO8Dh95JeiIif2p4k6dsFewLQsWGDbvtCSTdK+pkkRcQJSSfKtgWgS2023a+U9LGkx22/bntdM8jhK2yvtL3ddt1TuwAMq03Qz5E0V9IjETFH0ueS1pz5IEYyAf2rTdAPSDoQEa82H29SL/gAxolhgx4RH0p63/bs5lOLJO0u2hWATrV91f1uSeubV9z3SbqrXEsAutYq6BGxUxL73sA4xZFxQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSGIjZa7WtXLmyar377ruvar2hoaGq9ZYtW1a13qBj9hqQFEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpDAsEG3Pdv2ztNuR22vrtEcgG4Me824iHhb0rWSZHuCpIOSNhfuC0CHRrrpvkjSuxHxXolmAJQx0qAvl7ShRCMAymkd9Oaa7kslbfw/X2f2GtCn2g5wkKRbJO2IiI/O9sWIWCtprTT4p6kC481INt1XiM12YFxqFfRmTPJiSc+VbQdACW1HMn0u6TuFewFQCEfGAQkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCZSavfaxpNGcs36xpE86bqcfalGPerXqXRERl5z5ySJBHy3b2yNi/qDVoh71xroem+5AAgQdSKDfgr52QGtRj3pjWq+v9tEBlNFva3QABRB0IAGCDiRA0IEECDqQwH8An6mM7cqa+WgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlgQkeQbEtOE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ail5xtglEtbm"
      },
      "source": [
        "#Exactitud\n",
        "Se puede calcular en fraccción (proporción) - con el parámetro *normalize* por defecto.\n",
        "\n",
        "Se puede calcular en número de aciertos - con el parámetro *normalize = False*.\n",
        "\n",
        "$$exactitud(y,\\hat{y}) = \\frac{1}{n} \\sum_{i=0}^{n-1} 1(\\hat{y_{i}}=y_{i}),$$\n",
        "\n",
        "siendo $n$ el número total de ejemplos (instancias)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoIqCHutExMs",
        "outputId": "5e2ef522-170c-4c18-c0b5-784572925c10"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = [0, 1, 2, 3]\n",
        "y_true = [0, 1, 2, 3]\n",
        "accuracy_score(y_true, y_pred)\n",
        "\n",
        "accuracy_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GexSrptdNH5v"
      },
      "source": [
        "**Ejercicio Práctico**: Cuando hay datasets no balanceados, la exactitud no es una buena métrica, pues puede indicar falsamente un buen rendimiento. En estos casos es mejor usar la función [*balanced_accuracy_score*](https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score). Usar el *dataset* iris, desbalancearlo a propósito y observar cómo cambia la exactitud. Después usar la función *balanced_accuracy_score* y reportar el cambio en la métrica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II6uJ9mrEyUy",
        "outputId": "d9004f82-9c75-4130-c6c0-b92bfbfbea4b"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "data.target[[10, 25, 50]]\n",
        "\n",
        "list(data.target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['setosa', 'versicolor', 'virginica']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q739Lt5pEylC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVCAV7zRQ0Z0"
      },
      "source": [
        "#Precisión\n",
        "\n",
        "Podemos pensar en la precisión como la habilidad que tiene un clasificador de *NO ASIGNAR* falsos positivos (ejemplos clasificados como positivos que *en realidad* son negativos). En otras palabras, la métrica mide qué tan *preciso* es el clasificador para encontrar verdaderos positivos.\n",
        "\n",
        "Matemáticamente la precisión se ve así:\n",
        "\n",
        "$$P = \\frac{T_p}{T_p + F_p},$$\n",
        "\n",
        "con:\n",
        "\n",
        "$T_p \\Rightarrow$ Veraderos positivos\n",
        "\n",
        "$F_p \\Rightarrow$ Falsos positivos\n",
        "\n",
        "Pregunta: ¿Cuál es el valor más alto posible? ¿El más bajo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRgGMGUMQ3tT",
        "outputId": "fca5501e-7873-464b-a2be-0a67710590ea"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "y_true = [0, 1, 0, 0, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1]\n",
        "precision_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYjrx0wrWEMi"
      },
      "source": [
        "$$P = \\frac{1}{1+1}=0.5$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmiPHnMvVSp9"
      },
      "source": [
        "**Ejercicio Práctico**: Probar con diferentes opciones para el parámetro *average*. Observar los resultados. ¿Puedes intuir qué hace cada una de las opciones?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exhtxlX2Q3eo"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "y_true = [0, 1, 2, 0, 1, 2]\n",
        "y_pred = [0, 2, 1, 0, 0, 1]\n",
        "precision_score(y_true, y_pred, average='macro')\n",
        "\n",
        "precision_score(y_true, y_pred, average='micro')\n",
        "\n",
        "precision_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "precision_score(y_true, y_pred, average=None)\n",
        "\n",
        "y_pred = [0, 0, 0, 0, 0, 0]\n",
        "precision_score(y_true, y_pred, average=None)\n",
        "\n",
        "precision_score(y_true, y_pred, average=None, zero_division=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZXDq4yzR8hs"
      },
      "source": [
        "#Recall\n",
        "\n",
        "Intuitivamente esta métrica nos indica la habilidad del clasificador para encontrar *todos* los ejemplos verdaderos positivos.\n",
        "\n",
        "Matemáticamente se ve así:\n",
        "\n",
        "$$R = \\frac{T_p}{T_p + F_n},$$\n",
        "\n",
        "con:\n",
        "\n",
        "$T_p \\Rightarrow$ Verdaderos positivos\n",
        "\n",
        "$F_n \\Rightarrow$ Falsos negativos\n",
        "\n",
        "Pregunta: ¿Cuál es el valor más alto posible? ¿El más bajo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtZ8UQSSR9kl",
        "outputId": "c81ba328-ca5e-4c55-b084-ab2f0b49bed5"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "y_true = [0, 1, 1, 0, 1, 0]\n",
        "y_pred = [0, 0, 1, 0, 0, 1]\n",
        "recall_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdeurUO2XRbi"
      },
      "source": [
        "$$R = \\frac{2}{2 + 1}\\approx 0.66$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnAVzqE7XdGW"
      },
      "source": [
        "**Ejercicio Práctico**: Probar con diferentes opciones para el parámetro *average*. Observar los resultados. ¿Puedes intuir qué hace cada una de las opciones?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-UDn8JXR9Dm",
        "outputId": "b256280e-26f8-47ed-806a-b45d97313883"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "y_true = [0, 1, 2, 0, 1, 2]\n",
        "y_pred = [0, 2, 1, 0, 0, 1]\n",
        "recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "recall_score(y_true, y_pred, average='micro')\n",
        "\n",
        "recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "recall_score(y_true, y_pred, average=None)\n",
        "\n",
        "y_true = [0, 0, 0, 0, 0, 0]\n",
        "recall_score(y_true, y_pred, average=None)\n",
        "\n",
        "recall_score(y_true, y_pred, average=None, zero_division=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5, 1. , 1. ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEyuAd99XaeA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-FpAAR6ZCGI"
      },
      "source": [
        "#Puntuación F1\n",
        "\n",
        "Interpretamos la puntuación F1 como el *pseudo*promedio ponderado (multiplicado por un factor) de la precisión y el *recall*.\n",
        "\n",
        "Matemáticamente se ve así:\n",
        "\n",
        "$$F1_{score}=2\\cdot \\frac{P\\cdot R}{P + R}$$\n",
        "\n",
        "Por lo tanto, un modelo obtiene buenos resultados en la puntuación F1 si los positivos predichos son realmente positivos (precisión) y no se equivoca con los positivos y los predice negativos (*recall*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6roFMGYZFJz",
        "outputId": "62356a18-5741-46d1-85ad-9b64f1d1022a"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = [0, 1, 0, 0, 1, 1]\n",
        "y_pred = [0, 0, 1, 0, 0, 1]\n",
        "f1_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqkwfeNIaqnU"
      },
      "source": [
        "$$P = \\frac{1}{1+1}=0.5$$\n",
        "\n",
        "$$R = \\frac{1}{1 + 2}\\approx 0.33$$\n",
        "\n",
        "$$F1 = 2\\cdot \\frac{0.5\\cdot 0.\\overline{33}}{0.5 + 0.\\overline{33}}=0.4$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UGg2L2_apri"
      },
      "source": [
        "**Ejercicio Práctico**: Probar con diferentes opciones para el parámetro *average*. Observar los resultados. ¿Puedes intuir qué hace cada una de las opciones?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIQ5BQQGaojR",
        "outputId": "b0f7e80b-c0b6-4655-8a0f-10d065ca7aab"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = [0, 1, 2, 0, 1, 2]\n",
        "y_pred = [0, 2, 1, 0, 0, 1]\n",
        "f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "f1_score(y_true, y_pred, average='micro')\n",
        "\n",
        "f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "f1_score(y_true, y_pred, average=None)\n",
        "\n",
        "y_true = [0, 0, 0, 0, 0, 0]\n",
        "y_pred = [0, 0, 0, 0, 0, 0]\n",
        "f1_score(y_true, y_pred, zero_division=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W1rTaDzZE65"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVE7DhrqcfJP"
      },
      "source": [
        "#**Selección de Características**\n",
        "\n",
        "**Pregunta**: ¿Cómo puedo ajustar el modelo a los atributos más relevantes?, ¿esto me entregará una mejor evaluación?\n",
        "\n",
        "1. Ingeniería de Características: Normalmente se aplica primero para generar características adicionales y luego se realiza la selección de características para eliminar características irrelevantes, redundantes o altamente correlacionadas. El proceso de seleccionar características sirve para reducir la dimensionalidad del problema de entrenamiento.\n",
        "\n",
        "2.  La función de Sklearn *VarianceThreshold* es un enfoque básico simple para la selección de características.\n",
        "\n",
        "3. Reducción de dimensiones: NCA (Neighborhood Components Analysis) basado en KNN (Ver curso: Cómo resolver problemas con aprendizaje supervisado) o PCA (Principal Component Analysis) que es el más popular (Ver curso: Cómo resolver problemas con aprendizaje no supervisado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L0fdivviUcP"
      },
      "source": [
        "#Umbral de Varianza\n",
        "\n",
        "**¿Qué hace la función?**\n",
        "\n",
        "De forma predeterminada, elimina todas las características de varianza cero, es decir, las características que tienen el mismo valor en todas las muestras.\n",
        "\n",
        "**¿Por qué es útil?**\n",
        "\n",
        "Nos permite eliminar información redundante que no añade información nueva.\n",
        "\n",
        "**Ejemplo**\n",
        "\n",
        "Supón que tienes un conjunto de datos con características booleanas y quieres eliminar todas las características que son uno o cero (activadas o desactivadas) en más del 80% de las muestras. Las características booleanas son variables aleatorias de Bernoulli, y la varianza de tales variables está dada por:\n",
        "\n",
        "$$VAR[X] = p(1-p) = 0.8(1-0.8)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUMsoTV5hgb8",
        "outputId": "1ca2b8af-5a02-4901-9d23-4aaf7d0a67f7"
      },
      "source": [
        "import numpy as np\n",
        "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
        "X = np.array(X)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 1 0]\n",
            " [0 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwrF5dq8hnXh",
        "outputId": "f9f54075-738d-4020-e361-9ca51132a571"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
        "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
        "sel.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [1, 0],\n",
              "       [0, 0],\n",
              "       [1, 1],\n",
              "       [1, 0],\n",
              "       [1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCjazQl1mgzW"
      },
      "source": [
        "El resultado es que se ha eliminado la primera columna, que tiene una probabilidad $p = 5/6 > 0.8$ de contener un cero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-Yx3SQnEy0C"
      },
      "source": [
        "#Lecturas recomendadas\n",
        "\n",
        "**Inglés**\n",
        "1.   [Various ways to evaluate a machine learning model’s performance](https://towardsdatascience.com/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15)\n",
        "2.   [Metrics to Evaluate your Machine Learning Algorithm](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234)\n",
        "\n",
        "**Español**\n",
        "1. [Ingeniería de características en ciencia de datos](https://docs.microsoft.com/es-es/azure/machine-learning/team-data-science-process/create-features)\n",
        "\n",
        "2. [Cómo es trabajar de Científico de Datos: Ejemplo de un proyecto](https://machinelearningenespanol.com/2020/11/25/ejercicios-practicos-de-machine-learning/)\n",
        "\n",
        "3. [Evaluación de la precisión del modelo](https://docs.aws.amazon.com/es_es/machine-learning/latest/dg/evaluating-model-accuracy.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TQr2w3rE1nH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}